# -*- coding: utf-8 -*-
"""Capstone - Telecommunication Customer Churn - With Comments.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t0uyzDSWdWD6JFdpu33Kpbxco6-Ads--
"""

#Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Import Libraries for Machine Learning Model

from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import recall_score, confusion_matrix, classification_report, accuracy_score, confusion_matrix
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

#Load the dataset and print the head
df = pd.read_csv('TelcoCustomerChurn.csv')
df.head()

#Find out df size

print("Size - Rows and Columns")
df.shape

#Find the column names
print("\nColumn Names")
df.columns

#Describe Database
df.describe()

"""```
From describing the data, we can see that:
The average tenure of customers is 32 months.

The average monthly charges are just under $65
and the highest 25% bay over $89 a month.

The minimum payment was just over $18, and the max
was over $118, so there's a wide range in monthly payment ammounts.
```


"""

#Check what data type each column is
print("\nData Types")
df.dtypes

"""

```
Here we can notice that 'TotalCharges' is an object type, this doesn't make sense
as it represents the total charges in US currency.
```

"""

#Check for missing values
df.isnull().sum()

"""

```
At first glance, it doesn't look like there are any missing values.
But remember the data types, and how 'TotalCharges' was an Object type, not a float.

We need to convert it to a number type to actually catch any null values.
```

"""

#df_numeric_values = df.copy()
#df_numeric_values['TotalCharges'] = pd.to_numeric(df_numeric_values['TotalCharges'], errors='coerce')

#df_numeric_values.isnull().sum()

df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')

df.isnull().sum()

#Look at the 11 missing charges in 'Total Charges'
#df_numeric_values[df_numeric_values['TotalCharges'].isnull()]

df[df['TotalCharges'].isnull()]

"""

```
Notice that for everyone who's 'Total Charges' is null, they also have a tenure of 0.
This could be because they just started and they haven't paid yet.

These records won't tell us very much about customer patterns, and as there's only 11
records out of over 7,000, we'll be able to drop them without much impact.

While we're at it, we also don't need 'customerID' as it's not relevant to training the
model and is potentially personal identification.
```

"""

#Drop the null values, and the customerID column
#df_numeric_values.dropna(inplace=True)

#df = df_numeric_values.drop('customerID', axis=1, inplace=True)

df.dropna(inplace=True)

df = df.drop('customerID', axis=1)

#Check each column's null counts
df.isna().sum()

df.shape

#Divide the tenure into bins and assign them to groups
#Used Deepseek here to help debug, and figure out edge cases

labels = ["{0} - {1}".format(i,i+5) for i in range (1,72,6)]

df['TenureGroup'] = pd.cut(df['tenure'], range(1,74,6), right=False, labels=labels)

df['TenureGroup'].value_counts()

#Plot out the number of customers and whether they churned in bins of 6 months
plt.figure(figsize=(15, 8))
sns.countplot(x=df['TenureGroup'],hue='Churn',data=df, palette='rocket_r')
plt.title('Number of Churned Customers by Tenure (6 month Intervals)', fontsize = 12)
plt.show()

"""### **EXPLORATORY DATA ANALYSIS**"""

#Show count of each category for churn
df['Churn'].value_counts()

#Find the number of customers, how many have churned, and make a chart.
sns.countplot(x='Churn', data=df, hue= 'Churn', palette='rocket_r')
plt.title('Number of Churned Customers', fontsize = 12)
plt.show()

#Change Churn variable into a binary value
df['Churn'].replace(["Yes","No"], [1,0],inplace=True)
100*df[df['Churn']==1].shape[0]/df.shape[0]

"""


```
With a quick calculation, and from what we can see in the chart that around 26.6%
of the dataset is churn data, and not 50/50. This means that our data is imbalanced.
```


"""

#Find what percent of the dataset is Senior Citizens

100*df[df['SeniorCitizen']==1].shape[0]/df.shape[0]

"""

```
Only around 16% of the dataset are senior citizens, a majority
of our data comes from younger people.
```

"""

#Plot all the important countplots, excluding numerical columns for charges
#Learned about enumerate via youtube @ https://www.youtube.com/watch?v=joevqIG1I7k
#Used Deepseek to help debug

for i, column in enumerate(df.drop(columns=['Churn','TotalCharges','MonthlyCharges','tenure'])): #Excludes TotalCharges and MontlyCharges
    plt.figure(i,figsize=(15,6))
    sns.countplot(data=df,x=column,hue='Churn',palette='rocket_r')
    plt.show()

#One hot encoding
df = pd.get_dummies(df)

df.head(2)

#Create a correlation matrix of the dataset

plt.figure(figsize=(12,12))
sns.heatmap(df.corr(),cmap='coolwarm')

#Sort the most positively to negatively correlated variables with 'churn'
df.corr()['Churn'].sort_values(ascending = False)

#Plot a bar chart of all the variables sorted from most correlated to least.
plt.figure(figsize=(10,8))
df.corr()['Churn'].sort_values(ascending = False).drop(['Churn']).plot(kind='bar')
plt.show()

"""# CREATE MACHINE LEARNING MODELS

##Prepare, Train-Test Split, Balance Data, Train the Model, and Evaluate.

### MODELING USING UNDERSAMPLING

```
I originally didn't balance the dataset, and as a result my model, understandably
had issues. So the following is setting up the data, creating a function to return each model's evaluation scores, and then balancing the data by first, trying undersampling the data, and then by trying to balance the data by class weight.

Then seeing if both a logistic regression or a random forest model performs better for each balance method.
```
"""

#Import resample to help get smaller resample of majority class
from sklearn.utils import resample

df_majority = df[df['Churn'] == 0]
df_minority = df[df['Churn'] == 1]

#Downsize the majority no-churn class
df_majority_downsampled = resample(df_majority, replace=False, n_samples=len(df_minority), random_state=42) #Used deepseek to fix and add replace=False

#Combine for balanced dataset
df_balanced = pd.concat([df_majority_downsampled, df_minority])

#Split features from the churn target
X = df_balanced.drop('Churn', axis=1)
y = df_balanced['Churn']

#Train-Test Split 80/20
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

#Create a funtion to evaluate the models
def evaluate_model(name, model, X_test, y_test):
    y_pred = model.predict(X_test)
    print(f"\n{name} Evaluation:")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("Recall:", recall_score(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("\nClassification Report:\n", classification_report(y_test, y_pred))

    # Plot confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm',
                xticklabels=["No Churn", "Churn"],
                yticklabels=["No Churn", "Churn"])
    plt.title(f'Confusion Matrix - {name}')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

#Logistic Regression with Under sampling
log_model = LogisticRegression(max_iter=1000, solver='liblinear')
log_model.fit(X_train, y_train)
evaluate_model("Logistic Regression", log_model, X_test, y_test)

#Random Forest with under sampling
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
evaluate_model("Random Forest", rf_model, X_test, y_test)

"""### MODELING WITH BALANCED CLASSES
"""

# Split Features and Target
X = df.drop('Churn', axis=1)
y = df['Churn']

#Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

#Logistic Regression with Class Weight
log_model = LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear')
log_model.fit(X_train, y_train)
evaluate_model("Logistic Regression (Balanced)", log_model, X_test, y_test)

#Random Forest with Class Weight
rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)
rf_model.fit(X_train, y_train)
evaluate_model("Random Forest (Balanced)", rf_model, X_test, y_test)
